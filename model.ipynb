{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mobilenetv2 + SSD.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbsreEfjnQtP",
        "colab_type": "text"
      },
      "source": [
        "# Implementation of MobileNetv2+SSD<br>\n",
        "This is an implementation of the MobileNetv2 + SSD architecture for a relatively simpler task of determining bounding boxes for MNIST images embedded in a box. Each box contains only one digit(28x28 MNIST embedded into a 224x224 box) as of now, but the number of predictions per image can be expanded easily (the training outputs need to modified). Also, no data augmentation has been used till now (Colab kept crashing when I increased the dataset size beyond 1000, so the initial amount of data present was sufficient. The crashes might have been due to high traffic, but I haven't confirmed it).<p>\n",
        "In the earlier implementation, the ground truth data contained information about only one bounding box, which meant only one prediction per image ( reference https://colab.research.google.com/github/rs9899/mySSDimplementation/blob/master/MobileNetSSD_v2.ipynb#scrollTo=xWBzDsvkDqx5). For me, it also reduced the training signal and the model was overfitting. So I changed the outputs to a prediction for each default box (as it should be, from what I understood from the SSD paper). Although the initial implementation is good for the purposes for understanding the model.\n",
        "\n",
        "Comments mentioned throughout the code mention what needs to change if the model inputs or outputs are changed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdL2AL8yAi00",
        "colab_type": "text"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hvSY3X-AeFP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1039d725-6ddc-4032-f23c-a33ccd056bc8"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras \n",
        "import tensorflow as tf\n",
        "import numpy.matlib\n",
        "from PIL import Image\n",
        "from keras import backend as K\n",
        "from scipy.special import softmax\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import bottleneck"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFmrlFJ8uKCe",
        "colab_type": "text"
      },
      "source": [
        "Define Bottleneck Residual layer for MobileNet<br>\n",
        "Using the same parameters as mentioned in the paper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmwhyyS7CFyK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Bottleneck(keras.Model):\n",
        "  def __init__(\n",
        "      self,\n",
        "      expansion,\n",
        "      stride,\n",
        "      block_id,\n",
        "      filters,\n",
        "      alpha=1,\n",
        "      ):\n",
        "    super(Bottleneck,self).__init__(name = \"Bottleneck_\" + block_id)\n",
        "    self.stride = stride\n",
        "    self.expansion = expansion\n",
        "    self.alpha = alpha\n",
        "    self.output_channels = self.alpha * filters\n",
        "    self.out = None # there was some problem with the eager execution\n",
        "\n",
        "    prefix =  'Bottleneck_{}_'.format(block_id)\n",
        "    self.prefix = prefix\n",
        "    # expansion\n",
        "    self.expand_BN = layers.BatchNormalization(name = prefix + 'expand_BN')\n",
        "    self.expand_ReLU = layers.ReLU(max_value=6, name = prefix + 'expand_ReLU')\n",
        "\n",
        "    #conv\n",
        "    self.Conv = layers.DepthwiseConv2D(\n",
        "        kernel_size = 3,\n",
        "        padding='same',\n",
        "        strides = self.stride,\n",
        "        use_bias = False,\n",
        "        name = prefix + 'conv')\n",
        "    self.Conv_BN = layers.BatchNormalization(name = prefix + 'conv_BN')\n",
        "    self.Conv_ReLU = layers.ReLU(max_value=6, name = prefix + 'conv_ReLU')\n",
        "\n",
        "    #project\n",
        "    self.project = layers.Conv2D(\n",
        "        filters = self.output_channels,\n",
        "        kernel_size = 1,\n",
        "        use_bias = False,\n",
        "        name = 'contract')\n",
        "    self.project_BN = layers.BatchNormalization(name = prefix + 'contract_BN')\n",
        "\n",
        "    # dimensions need to be the same for residual connection\n",
        "    self.residual = layers.Add(name=prefix + 'residual')\n",
        "  \n",
        "  def build(self, input_shape):\n",
        "    self.d = input_shape[-1]\n",
        "    \n",
        "    self.expand = layers.Conv2D(\n",
        "        filters = self.expansion*self.d,\n",
        "        kernel_size = 1,\n",
        "        use_bias = False,\n",
        "        name = self.prefix+'expand')\n",
        "\n",
        "      \n",
        "  def call(self, inputs):\n",
        "\n",
        "    x = self.expand(inputs)\n",
        "    x = self.expand_BN(x)\n",
        "    x = self.expand_ReLU(x)\n",
        "    self.out = x\n",
        "    \n",
        "    x = self.Conv(x)\n",
        "    x = self.Conv_BN(x)\n",
        "    x = self.Conv_ReLU(x)\n",
        "\n",
        "    x = self.project(x)\n",
        "    x = self.project_BN(x)\n",
        "\n",
        "    if self.output_channels == self.d and self.stride == 1:\n",
        "      x = self.residual([inputs,x])\n",
        "\n",
        "    return x\n",
        "\n",
        "  def model(self):\n",
        "      x = keras.Input(shape=(28,28,3))\n",
        "      return keras.Model(inputs=[x], outputs=self.call(x))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfMYYpWpuQj4",
        "colab_type": "text"
      },
      "source": [
        "Define MobileNetv2<br>\n",
        "Same components as mentioned in the paper (the input image dimensions are a bit different)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYGagWE8T2Et",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#using the architecture mentioned in the paper\n",
        "class MobileNetv2(keras.Model):\n",
        "  def __init__(self, k = 11):\n",
        "    super(MobileNetv2,self).__init__()\n",
        "    self.conv_inp = layers.Conv2D(\n",
        "        filters = 32,\n",
        "        kernel_size = 3,\n",
        "        strides = (2,2),\n",
        "        padding='valid',\n",
        "        use_bias = False,\n",
        "        name = 'conv'\n",
        "    )\n",
        "    self.k = k    \n",
        "\n",
        "    self.pad = layers.ZeroPadding2D(padding=2,name='pad')\n",
        "    self.BN = layers.BatchNormalization(name='BN')\n",
        "    self.ReLU = layers.ReLU(max_value = 6, name = 'ReLU')\n",
        "    \n",
        "    self.B1_1 = Bottleneck(expansion = 1, filters = 16, stride = 1, block_id = 'B1_1')\n",
        "\n",
        "    self.B2_1 = Bottleneck(expansion = 6, filters = 24, stride = 2, block_id = 'B2_1')\n",
        "    self.B2_2 = Bottleneck(expansion = 6, filters = 24, stride = 1, block_id = 'B2_2')\n",
        "\n",
        "    self.B3_1 = Bottleneck(expansion = 6, filters = 32, stride = 2, block_id = 'B3_1')\n",
        "    self.B3_2 = Bottleneck(expansion = 6, filters = 32, stride = 1, block_id = 'B3_2')\n",
        "    self.B3_3 = Bottleneck(expansion = 6, filters = 32, stride = 1, block_id = 'B3_3')\n",
        "\n",
        "    self.B4_1 = Bottleneck(expansion = 6, filters = 64, stride = 2, block_id = 'B4_1')\n",
        "    self.B4_2 = Bottleneck(expansion = 6, filters = 64, stride = 1, block_id = 'B4_2')\n",
        "    self.B4_3 = Bottleneck(expansion = 6, filters = 64, stride = 1, block_id = 'B4_3')\n",
        "    self.B4_4 = Bottleneck(expansion = 6, filters = 64, stride = 1, block_id = 'B4_4')\n",
        "\n",
        "    self.B5_1 = Bottleneck(expansion = 6, filters = 96, stride = 1, block_id = 'B5_1')\n",
        "    self.B5_2 = Bottleneck(expansion = 6, filters = 96, stride = 1, block_id = 'B5_2')\n",
        "    self.B5_3 = Bottleneck(expansion = 6, filters = 96, stride = 1, block_id = 'B5_3')\n",
        "\n",
        "    self.B6_1 = Bottleneck(expansion = 6, filters = 160, stride = 2, block_id = 'B6_1')\n",
        "    self.B6_2 = Bottleneck(expansion = 6, filters = 160, stride = 1, block_id = 'B6_2')\n",
        "    self.B6_3 = Bottleneck(expansion = 6, filters = 160, stride = 1, block_id = 'B6_3')\n",
        "\n",
        "    self.B7_1 = Bottleneck(expansion = 6, filters = 320, stride = 1, block_id = 'B7_1')\n",
        "\n",
        "    self.conv_out = layers.Conv2D(\n",
        "        filters = 1280,\n",
        "        kernel_size = 1,\n",
        "        strides = (1,1),\n",
        "        use_bias = False,\n",
        "        name = 'conv_out'\n",
        "    )\n",
        "    self.avgpool = layers.AveragePooling2D(\n",
        "        pool_size = (7,7),\n",
        "        name='avg_pool'\n",
        "        )\n",
        "    \n",
        "    self.conv_seg = layers.Conv2D(\n",
        "        filters = self.k,\n",
        "        kernel_size = 1,\n",
        "        strides = (1,1),\n",
        "        use_bias = False,\n",
        "        name = 'conv_seg'\n",
        "    )\n",
        "\n",
        "  def call(self, inputs):\n",
        "    x = self.conv_inp(inputs)\n",
        "    x = self.BN(x)\n",
        "    x = self.ReLU(x)\n",
        "\n",
        "    x = self.B1_1(x)\n",
        "    x = self.B2_1(x)\n",
        "    x = self.B2_2(x)\n",
        "\n",
        "    x = self.B3_1(x)\n",
        "    x = self.B3_2(x)\n",
        "    x = self.B3_3(x)\n",
        "    \n",
        "    x = self.B4_1(x)\n",
        "    x = self.B4_2(x)\n",
        "    x = self.B4_3(x)\n",
        "    x = self.B4_4(x)\n",
        "    \n",
        "    x = self.B5_1(x)\n",
        "    x = self.B5_2(x)\n",
        "    x = self.B5_3(x)\n",
        "    \n",
        "    x = self.B6_1(x)\n",
        "    x = self.B6_2(x)\n",
        "    x = self.B6_3(x)\n",
        "    \n",
        "    x = self.B7_1(x)\n",
        "\n",
        "    x = self.conv_out(x)\n",
        "    x = self.avgpool(x)\n",
        "    c4 = self.conv_seg(x)\n",
        "\n",
        "    return c4\n",
        "\n",
        "  def model(self):\n",
        "      x = keras.Input(shape=(224,224,3))\n",
        "\n",
        "      return keras.Model(inputs=x, outputs=self.call(x))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05i7363EYwmP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "outputId": "d8434d3b-e85a-4481-b5bd-15751d6e9140"
      },
      "source": [
        "MobileNetv2().model().summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv (Conv2D)                (None, 111, 111, 32)      864       \n",
            "_________________________________________________________________\n",
            "BN (BatchNormalization)      (None, 111, 111, 32)      128       \n",
            "_________________________________________________________________\n",
            "ReLU (ReLU)                  (None, 111, 111, 32)      0         \n",
            "_________________________________________________________________\n",
            "Bottleneck_B1_1 (Bottleneck) (None, 111, 111, 16)      2144      \n",
            "_________________________________________________________________\n",
            "Bottleneck_B2_1 (Bottleneck) (None, 56, 56, 24)        5568      \n",
            "_________________________________________________________________\n",
            "Bottleneck_B2_2 (Bottleneck) (None, 56, 56, 24)        9456      \n",
            "_________________________________________________________________\n",
            "Bottleneck_B3_1 (Bottleneck) (None, 28, 28, 32)        10640     \n",
            "_________________________________________________________________\n",
            "Bottleneck_B3_2 (Bottleneck) (None, 28, 28, 32)        15680     \n",
            "_________________________________________________________________\n",
            "Bottleneck_B3_3 (Bottleneck) (None, 28, 28, 32)        15680     \n",
            "_________________________________________________________________\n",
            "Bottleneck_B4_1 (Bottleneck) (None, 14, 14, 64)        21952     \n",
            "_________________________________________________________________\n",
            "Bottleneck_B4_2 (Bottleneck) (None, 14, 14, 64)        55936     \n",
            "_________________________________________________________________\n",
            "Bottleneck_B4_3 (Bottleneck) (None, 14, 14, 64)        55936     \n",
            "_________________________________________________________________\n",
            "Bottleneck_B4_4 (Bottleneck) (None, 14, 14, 64)        55936     \n",
            "_________________________________________________________________\n",
            "Bottleneck_B5_1 (Bottleneck) (None, 14, 14, 96)        68352     \n",
            "_________________________________________________________________\n",
            "Bottleneck_B5_2 (Bottleneck) (None, 14, 14, 96)        120768    \n",
            "_________________________________________________________________\n",
            "Bottleneck_B5_3 (Bottleneck) (None, 14, 14, 96)        120768    \n",
            "_________________________________________________________________\n",
            "Bottleneck_B6_1 (Bottleneck) (None, 7, 7, 160)         157888    \n",
            "_________________________________________________________________\n",
            "Bottleneck_B6_2 (Bottleneck) (None, 7, 7, 160)         324160    \n",
            "_________________________________________________________________\n",
            "Bottleneck_B6_3 (Bottleneck) (None, 7, 7, 160)         324160    \n",
            "_________________________________________________________________\n",
            "Bottleneck_B7_1 (Bottleneck) (None, 7, 7, 320)         478400    \n",
            "_________________________________________________________________\n",
            "conv_out (Conv2D)            (None, 7, 7, 1280)        409600    \n",
            "_________________________________________________________________\n",
            "avg_pool (AveragePooling2D)  (None, 1, 1, 1280)        0         \n",
            "_________________________________________________________________\n",
            "conv_seg (Conv2D)            (None, 1, 1, 11)          14080     \n",
            "=================================================================\n",
            "Total params: 2,268,096\n",
            "Trainable params: 2,236,480\n",
            "Non-trainable params: 31,616\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "II03ZRu17FnE",
        "colab_type": "text"
      },
      "source": [
        "Defining SSD<br>\n",
        "The default number of boxes per layer and resolution of each layer is different, since we are working with MNIST data and 224x224 image sizes.<p>\n",
        "To change the number of boxes per layer and layerWidths, some constraints need to be kept in mind which are mentioned in the later sections"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYD2gfR9O8L0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SSD(keras.Model):\n",
        "  def __init__(self, numBoxes=[4,6,6,6,4,4], layerWidth=[28,14,7,4,2,1], k = 10+1+4):\n",
        "    super(SSD,self).__init__()\n",
        "    self.classes = k\n",
        "    self.featureMaps = 6\n",
        "    self.MobileNet = MobileNetv2(k=k)\n",
        "    self.numBoxes = numBoxes\n",
        "    self.layerWidth = layerWidth\n",
        "    self.features = [None for _ in range(self.featureMaps)]\n",
        "    self.classifiers = [None for _ in range(self.featureMaps)]\n",
        "    \n",
        "    self.conv1_1 = layers.Conv2D(256,1,name='SSD_conv_1_1')\n",
        "    self.conv1_2 = layers.Conv2D(512,3,strides=(2,2),padding='same',name='SSD_conv_1_2')\n",
        "\n",
        "    self.conv2_1 = layers.Conv2D(128,1,name='SSD_conv_2_1')\n",
        "    self.conv2_2 = layers.Conv2D(256,3,strides=(2,2),padding='same',name='SSD_conv_2_2')\n",
        "    \n",
        "    self.conv3_1 = layers.Conv2D(128,1,name='SSD_conv_3_1')\n",
        "    self.conv3_2 = layers.Conv2D(256,3,strides=(1,1),name='SSD_conv_3_2')\n",
        "    \n",
        "    self.conv4_1 = layers.Conv2D(128,1,name='SSD_conv_4_1')\n",
        "    self.conv4_2 = layers.Conv2D(256,2,strides=(1,1),name='SSD_conv_4_2') # changed the kernel size to 2 since the output of the previous layer has width 3\n",
        "\n",
        "    self.conv = []\n",
        "    self.reshape = []\n",
        "    for i in range(self.featureMaps):\n",
        "      self.conv.append(layers.Conv2D(self.numBoxes[i]*self.classes,3,padding='same',name='Classification_'+str(i)))\n",
        "      self.reshape.append(layers.Reshape((self.layerWidth[i]* self.layerWidth[i] * self.numBoxes[i],self.classes),name='Reshape_classification_'+str(i)))\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.MobileNet.build(input_shape)\n",
        "  \n",
        "  def call(self,inputs):\n",
        "    x = inputs\n",
        "    x = self.MobileNet(x)\n",
        "\n",
        "    # get the convolved images at different resolutions\n",
        "    self.features[0] = self.MobileNet.get_layer('Bottleneck_B4_1').out\n",
        "    self.features[1] = self.MobileNet.get_layer('Bottleneck_B5_3').out\n",
        "    self.features[2] = self.conv1_2(self.conv1_1(self.features[1]))\n",
        "    self.features[3] = self.conv2_2(self.conv2_1(self.features[2]))\n",
        "    self.features[4] = self.conv3_2(self.conv3_1(self.features[3]))\n",
        "    self.features[5] = self.conv4_2(self.conv4_1(self.features[4]))\n",
        "\n",
        "    for i in range(self.featureMaps):\n",
        "    # for each feature map, create predictions according to the number of boxes for that layer and the number of output channels\n",
        "      x = self.conv[i](self.features[i])\n",
        "      x = self.reshape[i](x)\n",
        "      self.classifiers[i] = x\n",
        "    \n",
        "    # concatenate all the classifiers\n",
        "    x = layers.concatenate(self.classifiers, axis = -2, name='concatenate')\n",
        "    return x\n",
        "\n",
        "\n",
        "  def model(self):\n",
        "      x = keras.Input(shape=(224,224,3))\n",
        "\n",
        "      return keras.Model(inputs=x, outputs=self.call(x))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29A_FW-GxK4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_CLASSES = 10\n",
        "# the first 2 dimensions should be equal to width of the output from the bottleneck expand ReLU at the (4,1) and (5,3) respectively.\n",
        "# the dimensions after the second one are determined by the convolutions written inside the SSD (conv1_2, conv2_2, conv3_3, conv4_2)\n",
        "layerWidths = [28,14,7,4,2,1]\n",
        "numBoxes = [3,3,3,3,3,3]\n",
        "assert len(numBoxes) == len(layerWidths) # numBoxes for each layer and each layer has a specific width\n",
        "outputChannels = NUM_CLASSES + 1 + 4 # 10 classes + background + cx,cy,h,w\n",
        "assert outputChannels - NUM_CLASSES == 5"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmOfPVIjCkuP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5fdfe35e-e5d8-4f1f-c112-da87335a2f74"
      },
      "source": [
        "model = SSD(numBoxes=numBoxes, layerWidth=layerWidths, k = outputChannels)\n",
        "model.model().summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv (Conv2D)                   (None, 111, 111, 32) 864         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "BN (BatchNormalization)         (None, 111, 111, 32) 128         conv[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "ReLU (ReLU)                     (None, 111, 111, 32) 0           BN[0][0]                         \n",
            "__________________________________________________________________________________________________\n",
            "Bottleneck_B1_1 (Bottleneck)    (None, 111, 111, 16) 2144        ReLU[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "Bottleneck_B2_1 (Bottleneck)    (None, 56, 56, 24)   5568        Bottleneck_B1_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "Bottleneck_B2_2 (Bottleneck)    (None, 56, 56, 24)   9456        Bottleneck_B2_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "Bottleneck_B3_1 (Bottleneck)    (None, 28, 28, 32)   10640       Bottleneck_B2_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "Bottleneck_B3_2 (Bottleneck)    (None, 28, 28, 32)   15680       Bottleneck_B3_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "Bottleneck_B3_3 (Bottleneck)    (None, 28, 28, 32)   15680       Bottleneck_B3_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "Bottleneck_B4_1 (Bottleneck)    (None, 14, 14, 64)   21952       Bottleneck_B3_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "Bottleneck_B4_2 (Bottleneck)    (None, 14, 14, 64)   55936       Bottleneck_B4_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "Bottleneck_B4_3 (Bottleneck)    (None, 14, 14, 64)   55936       Bottleneck_B4_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "Bottleneck_B4_4 (Bottleneck)    (None, 14, 14, 64)   55936       Bottleneck_B4_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "Bottleneck_B5_1 (Bottleneck)    (None, 14, 14, 96)   68352       Bottleneck_B4_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "Bottleneck_B5_2 (Bottleneck)    (None, 14, 14, 96)   120768      Bottleneck_B5_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "Bottleneck_B5_3_expand (Conv2D) (None, 14, 14, 576)  55296       Bottleneck_B5_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "Bottleneck_B5_3_expand_BN (Batc (None, 14, 14, 576)  2304        Bottleneck_B5_3_expand[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "Bottleneck_B5_3_expand_ReLU (Re (None, 14, 14, 576)  0           Bottleneck_B5_3_expand_BN[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "SSD_conv_1_1 (Conv2D)           (None, 14, 14, 256)  147712      Bottleneck_B5_3_expand_ReLU[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "SSD_conv_1_2 (Conv2D)           (None, 7, 7, 512)    1180160     SSD_conv_1_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "SSD_conv_2_1 (Conv2D)           (None, 7, 7, 128)    65664       SSD_conv_1_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "SSD_conv_2_2 (Conv2D)           (None, 4, 4, 256)    295168      SSD_conv_2_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "SSD_conv_3_1 (Conv2D)           (None, 4, 4, 128)    32896       SSD_conv_2_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "Bottleneck_B4_1_expand (Conv2D) (None, 28, 28, 192)  6144        Bottleneck_B3_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "SSD_conv_3_2 (Conv2D)           (None, 2, 2, 256)    295168      SSD_conv_3_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "Bottleneck_B4_1_expand_BN (Batc (None, 28, 28, 192)  768         Bottleneck_B4_1_expand[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "SSD_conv_4_1 (Conv2D)           (None, 2, 2, 128)    32896       SSD_conv_3_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "Bottleneck_B4_1_expand_ReLU (Re (None, 28, 28, 192)  0           Bottleneck_B4_1_expand_BN[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "SSD_conv_4_2 (Conv2D)           (None, 1, 1, 256)    131328      SSD_conv_4_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "Classification_0 (Conv2D)       (None, 28, 28, 45)   77805       Bottleneck_B4_1_expand_ReLU[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Classification_1 (Conv2D)       (None, 14, 14, 45)   233325      Bottleneck_B5_3_expand_ReLU[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "Classification_2 (Conv2D)       (None, 7, 7, 45)     207405      SSD_conv_1_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "Classification_3 (Conv2D)       (None, 4, 4, 45)     103725      SSD_conv_2_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "Classification_4 (Conv2D)       (None, 2, 2, 45)     103725      SSD_conv_3_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "Classification_5 (Conv2D)       (None, 1, 1, 45)     103725      SSD_conv_4_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "Reshape_classification_0 (Resha (None, 2352, 15)     0           Classification_0[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Reshape_classification_1 (Resha (None, 588, 15)      0           Classification_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Reshape_classification_2 (Resha (None, 147, 15)      0           Classification_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Reshape_classification_3 (Resha (None, 48, 15)       0           Classification_3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Reshape_classification_4 (Resha (None, 12, 15)       0           Classification_4[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "Reshape_classification_5 (Resha (None, 3, 15)        0           Classification_5[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3150, 15)     0           Reshape_classification_0[0][0]   \n",
            "                                                                 Reshape_classification_1[0][0]   \n",
            "                                                                 Reshape_classification_2[0][0]   \n",
            "                                                                 Reshape_classification_3[0][0]   \n",
            "                                                                 Reshape_classification_4[0][0]   \n",
            "                                                                 Reshape_classification_5[0][0]   \n",
            "==================================================================================================\n",
            "Total params: 3,507,342\n",
            "Trainable params: 3,492,494\n",
            "Non-trainable params: 14,848\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RA7NxfQ7_G6",
        "colab_type": "text"
      },
      "source": [
        "Creating boxes and IoU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRYi7Ez7UzpH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# I have used less varying custom scales and aspect ratios here, since the dataset is already uniform\n",
        "#IMPORTANT: before changing the scales and aspect ratios, read the comment below\n",
        "\n",
        "# number of scales is equal to the number of different resolutions ie num of layer widths\n",
        "# for a given resolution, we have different aspect ratios\n",
        "# num(scales) = num(layerWidth) = num(numBoxes) and num(asp_ratios) = numBoxes[i]\n",
        "MinScale = .1 # Min and Max scale given as percentage\n",
        "MaxScale = 1.5\n",
        "scales = [ MinScale + x/len(layerWidths) * (MaxScale-MinScale) for x in range(len(layerWidths)) ]\n",
        "scales = scales[::-1] # reversing the order because the layerWidths go from high to low (lower to higher resoltuion)\n",
        "\n",
        "asp = [0.5,1.0,1.5]\n",
        "asp1 = [x**0.5 for x in asp]\n",
        "asp2 = [1/x for x in asp1]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwR_TIbzYCix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_SIZE = 224"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wA_IhnyrUl4S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "af7460ef-2baf-4430-c1fd-bb068709e5fe"
      },
      "source": [
        "# should be equal to the 1st dimension in the output layer of the SSD model\n",
        "BOXES = sum([a*a*b for a,b in zip(layerWidths,numBoxes)])\n",
        "centres = np.zeros((BOXES,2))\n",
        "hw = np.zeros((BOXES,2))\n",
        "boxes = np.zeros((BOXES,4))\n",
        "print(BOXES)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A1xGMrXVX18",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculating the default box centres and height, width\n",
        "idx = 0\n",
        "\n",
        "for gridSize, numBox, scale in zip(layerWidths,numBoxes,scales):\n",
        "  step_size = IMG_SIZE*1.0/gridSize\n",
        "  for i in range(gridSize):\n",
        "    for j in range(gridSize):\n",
        "      pos = idx + (i*gridSize+j) * numBox\n",
        "      # centre is the same for all aspect ratios(=numBox)\n",
        "      centres[ pos : pos + numBox , :] = i*step_size + step_size/2, j*step_size + step_size/2\n",
        "      # height and width vary according to the scale and aspect ratio\n",
        "      # zip asepct ratios and then scale them by the scaling factor\n",
        "      hw[ pos : pos + numBox , :] = np.multiply(gridSize*scale, np.squeeze(np.dstack([asp1,asp2]),axis=0))[:numBox,:]\n",
        "\n",
        "  idx += gridSize*gridSize*numBox "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xp9CrasJhGXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (x,y) co-ordinates of top left and bottom right\n",
        "# This actually is not used anywhere. centres[] and hw[] are a good enough substitute\n",
        "boxes[:,0] = centres[:,0] - hw[:,0]/2\n",
        "boxes[:,1] = centres[:,1] - hw[:,1]/2\n",
        "boxes[:,2] = centres[:,0] + hw[:,0]/2\n",
        "boxes[:,3] = centres[:,1] + hw[:,1]/2"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJSIPHPMh3N2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate IoU for a set of search boxes and default boxes\n",
        "def IoU(box1, box2):\n",
        "  box1 = box1.astype(np.float64)\n",
        "  box2 = box2.astype(np.float64)\n",
        "  # find the left and right co-ordinates of the edges. Min should be less than Max for non zero overlap\n",
        "  xmin = np.maximum(box1[:,0],box2[:,0])\n",
        "  xmax = np.minimum(box1[:,2],box2[:,2])\n",
        "  ymin = np.maximum(box1[:,1],box2[:,1])\n",
        "  ymax = np.minimum(box1[:,3],box2[:,3])\n",
        "\n",
        "  intersection = np.abs(np.maximum(xmax-xmin,0) * np.maximum(ymax-ymin,0))\n",
        "  boxArea1 = np.abs((box1[:,2] - box1[:,0]) * (box1[:,3] - box1[:,1]))\n",
        "  boxArea2 = np.abs((box2[:,2] - box2[:,0]) * (box2[:,3] - box2[:,1]))\n",
        "  unionArea = boxArea1 + boxArea2 - intersection\n",
        "  assert (unionArea > 0).all()\n",
        "  iou = intersection / unionArea\n",
        "\n",
        "  return iou"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOcpxxIQipbA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# give the index of the box correpsonding to the IoUs > threshold (=0.5) \n",
        "def bestIoU(searchBox):\n",
        "  return np.argwhere(IoU(numpy.matlib.repmat(searchBox,BOXES,1), boxes) > 0.5)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm2k4c5Ik_BX",
        "colab_type": "text"
      },
      "source": [
        "Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h07BGB7-k9te",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAINSIZE = 600\n",
        "TESTSIZE = 100"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wkZPTKgGq08N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train = x_train[:TRAINSIZE , : , :]\n",
        "y_train = y_train[:TRAINSIZE]\n",
        "x_test = x_test[:TESTSIZE , : , :]\n",
        "y_test = y_test[:TESTSIZE]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEgx1Sdcq7yJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# take mnist x and y pairs and convert to input, output pairs for the MobileNetv2+SSD model\n",
        "def convert(x,y):\n",
        "  MNIST_SIZE = x.shape[-1]\n",
        "  # create a 2D array of top left corners for the mnist image to be placed\n",
        "  corner = np.random.randint(IMG_SIZE - MNIST_SIZE, size=(x.shape[0],2))\n",
        "\n",
        "  # create a blank canvas for the input with the required dimension\n",
        "  input = np.zeros((x.shape[0], IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "  # replacing a part by RGB version of MNIST\n",
        "  for i in range(x.shape[0]):\n",
        "    lx = int(corner[i,0])\n",
        "    ly = int(corner[i,1])\n",
        "    input[i,lx:lx + MNIST_SIZE, ly:ly+MNIST_SIZE,:] = np.repeat(np.expand_dims(np.array(x[i,:,:]),axis=-1),3,axis=-1)\n",
        "\n",
        "  # for each default box, there are 5 values: class number and delta cx,cy,h,w\n",
        "  output = np.zeros((y.shape[0],BOXES,1+4))\n",
        "  output[:,:,0] = NUM_CLASSES # defaulting class labels for all boxes to background initially\n",
        "  for i in range(x.shape[0]):\n",
        "    bbox = np.zeros(4)\n",
        "    bbox[:2] = corner[i]\n",
        "    bbox[2:] = corner[i] + (MNIST_SIZE,MNIST_SIZE)\n",
        "    # for all default boxes which have IoU > threshold, set the delta values and class number\n",
        "    box_idx = bestIoU(bbox).astype(np.uint16)\n",
        "    output[i,box_idx,0] = y[i]\n",
        "    output[i,box_idx,1] = (bbox[0] + bbox[2])/2.0 - centres[box_idx,0]\n",
        "    output[i,box_idx,2] = (bbox[1] + bbox[3])/2.0 - centres[box_idx,1]\n",
        "    output[i,box_idx,3] = MNIST_SIZE - hw[box_idx,0]\n",
        "    output[i,box_idx,4] = MNIST_SIZE - hw[box_idx,1]\n",
        "\n",
        "  return input, output\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sk_z17wV3Bj5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_x, test_y = convert(x_test,y_test)\n",
        "train_x, train_y = convert(x_train,y_train)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAwnJnu4qE0P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "27116f08-73e6-42e7-c8d8-daac27654afc"
      },
      "source": [
        "# checking if the inputs prepared are correct or not\n",
        "r = np.random.randint(0,train_x.shape[0])\n",
        "img = train_x[r,:,:,:].copy()\n",
        "img_y = train_y[r]\n",
        "\n",
        "im = np.array(Image.fromarray(img.astype(np.uint8)))\n",
        "fig,ax = plt.subplots(1)\n",
        "ax.imshow(im)\n",
        "\n",
        "# find all boxes where class label is not background\n",
        "idx = np.argwhere(img_y[:,0] != NUM_CLASSES)[:,0]\n",
        "print('Number of boxes with IoU > 0.5:',idx.shape[0])\n",
        "print('Green box: ground truth. Red box: default boxes with IoU > threshold')\n",
        "\n",
        "#calculating the ground truth bounding boxes\n",
        "gt = np.zeros(4,dtype=np.uint16)\n",
        "gt[:2] = (img_y[idx[0],1:3] + centres[idx[0],:2])\n",
        "gt[2:] = (img_y[idx[0],3:] + hw[idx[0],:])\n",
        "\n",
        "# for some reason, x and y are inverted\n",
        "rect = patches.Rectangle((gt[1]-gt[3]/2,gt[0]-gt[2]/2),gt[3],gt[2],linewidth=5,edgecolor='g',facecolor='none')\n",
        "ax.add_patch(rect)\n",
        "\n",
        "# showing all the boxes with IoU > 0.5\n",
        "for i in idx:\n",
        "  rect = patches.Rectangle((centres[i][1]-hw[i,1]/2,centres[i][0]-hw[i,0]/2),hw[i,1],hw[i,0],linewidth=1,edgecolor='r',facecolor='none')\n",
        "  ax.add_patch(rect)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of boxes with IoU > 0.5: 6\n",
            "Green box: ground truth. Red box: default boxes with IoU > threshold\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nI7mXjS8zA9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "88b50f5a-8931-4f30-eb69-f211e964d690"
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y))\n",
        "print(train_dataset.element_spec)\n",
        "print(test_dataset.element_spec)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(TensorSpec(shape=(224, 224, 3), dtype=tf.float64, name=None), TensorSpec(shape=(3150, 5), dtype=tf.float64, name=None))\n",
            "(TensorSpec(shape=(224, 224, 3), dtype=tf.float64, name=None), TensorSpec(shape=(3150, 5), dtype=tf.float64, name=None))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyX8dnwQ8_1k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 10\n",
        "SHUFFLE_BUFFER_SIZE = 60\n",
        "\n",
        "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE,drop_remainder=True)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE,drop_remainder=True)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EeBg_g29GLU",
        "colab_type": "text"
      },
      "source": [
        "LOSS FUNCTION<br>\n",
        "Hard negative mining hasn't been done here<br>\n",
        "Initial idea was to assign weights to background classes, but there is some problem in that approach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMEpljzd9CxT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# label is not required here in the standard implementation\n",
        "# calculate the smooth L1 loss\n",
        "def smoothL1(x,y,label):\n",
        "  diff = K.abs(x-y) #* K.switch(label == 10, label*1.0/BOXES, label)\n",
        "  result = K.switch(diff < 1, 0.5 * diff**2, diff - 0.5)\n",
        "  return K.mean(result)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fSUhh8O_DsK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def confidenceLoss(y,label):\n",
        "  unweighted_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(label, y)\n",
        "  # class_weights = tf.constant([[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0/BOXES]]*BOXES])\n",
        "  # weights = tf.reduce_sum(class_weights * y, axis = -1)\n",
        "  # weighted_loss = unweighted_loss * weights\n",
        "  return K.mean(unweighted_loss)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gn0xh6OX_BvN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Loss(gt,y):\n",
        "  # shape of y is n * BOXES * output_channels\n",
        "  # shape of gt is n * BOXES * 5 \n",
        "  loss = 0\n",
        "  # localisation loss\n",
        "  loss += smoothL1(y[:,:,-4:],gt[:,:,-4:],gt[:,:,0:1])\n",
        "  # confidence loss\n",
        "  loss += confidenceLoss(y[:,:,:-4],tf.cast(gt[:,:,0],tf.int32))\n",
        "  return loss"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8_O3V8DB_Gk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_learning_rate = 0.001\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=base_learning_rate),loss=Loss)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7pp6Fp9DDWm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "39ca0340-fe39-4016-da7d-1ca95148010b"
      },
      "source": [
        "history = model.fit(train_dataset,\n",
        "                    epochs=25,\n",
        "                    validation_data = test_dataset)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "WARNING:tensorflow:Layer ssd is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B5_3/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_expand/kernel:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_2/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_expand/kernel:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_3/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_expand/kernel:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B7_1/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_expand/kernel:0', 'mobile_netv2_1/conv_out/kernel:0', 'mobile_netv2_1/conv_seg/kernel:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B5_3/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_expand/kernel:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_2/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_expand/kernel:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_3/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_expand/kernel:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B7_1/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_expand/kernel:0', 'mobile_netv2_1/conv_out/kernel:0', 'mobile_netv2_1/conv_seg/kernel:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B5_3/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_expand/kernel:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_2/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_expand/kernel:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_3/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_expand/kernel:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B7_1/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_expand/kernel:0', 'mobile_netv2_1/conv_out/kernel:0', 'mobile_netv2_1/conv_seg/kernel:0'] when minimizing the loss.\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B5_3/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B5_3/Bottleneck_B5_3_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_1/Bottleneck_B6_1_expand/kernel:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_2/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_2/Bottleneck_B6_2_expand/kernel:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_3/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B6_3/Bottleneck_B6_3_expand/kernel:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_expand_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_expand_BN/beta:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_conv/depthwise_kernel:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_conv_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_conv_BN/beta:0', 'mobile_netv2_1/Bottleneck_B7_1/contract/kernel:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_contract_BN/gamma:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_contract_BN/beta:0', 'mobile_netv2_1/Bottleneck_B7_1/Bottleneck_B7_1_expand/kernel:0', 'mobile_netv2_1/conv_out/kernel:0', 'mobile_netv2_1/conv_seg/kernel:0'] when minimizing the loss.\n",
            "60/60 [==============================] - 11s 181ms/step - loss: 0.3415 - val_loss: 0.2681\n",
            "Epoch 2/25\n",
            "60/60 [==============================] - 10s 165ms/step - loss: 0.0890 - val_loss: 0.0674\n",
            "Epoch 3/25\n",
            "60/60 [==============================] - 10s 165ms/step - loss: 0.0528 - val_loss: 0.0564\n",
            "Epoch 4/25\n",
            "60/60 [==============================] - 10s 166ms/step - loss: 0.0457 - val_loss: 0.0455\n",
            "Epoch 5/25\n",
            "60/60 [==============================] - 10s 166ms/step - loss: 0.0764 - val_loss: 0.0467\n",
            "Epoch 6/25\n",
            "60/60 [==============================] - 10s 165ms/step - loss: 0.0215 - val_loss: 0.0264\n",
            "Epoch 7/25\n",
            "60/60 [==============================] - 10s 166ms/step - loss: 0.0241 - val_loss: 0.0191\n",
            "Epoch 8/25\n",
            "60/60 [==============================] - 10s 165ms/step - loss: 0.0384 - val_loss: 0.0180\n",
            "Epoch 9/25\n",
            "60/60 [==============================] - 10s 166ms/step - loss: 0.0250 - val_loss: 0.0160\n",
            "Epoch 10/25\n",
            "60/60 [==============================] - 10s 166ms/step - loss: 0.0333 - val_loss: 0.0145\n",
            "Epoch 11/25\n",
            "60/60 [==============================] - 10s 165ms/step - loss: 0.0143 - val_loss: 0.0134\n",
            "Epoch 12/25\n",
            "60/60 [==============================] - 10s 165ms/step - loss: 0.0207 - val_loss: 0.0144\n",
            "Epoch 13/25\n",
            "60/60 [==============================] - 10s 165ms/step - loss: 0.0164 - val_loss: 0.0134\n",
            "Epoch 14/25\n",
            "60/60 [==============================] - 10s 166ms/step - loss: 0.0162 - val_loss: 0.0130\n",
            "Epoch 15/25\n",
            "60/60 [==============================] - 10s 166ms/step - loss: 0.0135 - val_loss: 0.0124\n",
            "Epoch 16/25\n",
            "60/60 [==============================] - 10s 165ms/step - loss: 0.0111 - val_loss: 0.0113\n",
            "Epoch 17/25\n",
            "60/60 [==============================] - 10s 166ms/step - loss: 0.0126 - val_loss: 0.0107\n",
            "Epoch 18/25\n",
            "60/60 [==============================] - 10s 165ms/step - loss: 0.0115 - val_loss: 0.0110\n",
            "Epoch 19/25\n",
            "60/60 [==============================] - 10s 165ms/step - loss: 0.0125 - val_loss: 0.0104\n",
            "Epoch 20/25\n",
            "60/60 [==============================] - 10s 165ms/step - loss: 0.0086 - val_loss: 0.0102\n",
            "Epoch 21/25\n",
            "60/60 [==============================] - 10s 165ms/step - loss: 0.0137 - val_loss: 0.0104\n",
            "Epoch 22/25\n",
            "60/60 [==============================] - 10s 166ms/step - loss: 0.0114 - val_loss: 0.0149\n",
            "Epoch 23/25\n",
            "60/60 [==============================] - 10s 165ms/step - loss: 0.0076 - val_loss: 0.0103\n",
            "Epoch 24/25\n",
            "60/60 [==============================] - 10s 165ms/step - loss: 0.0078 - val_loss: 0.0093\n",
            "Epoch 25/25\n",
            "60/60 [==============================] - 10s 165ms/step - loss: 0.0092 - val_loss: 0.0098\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_n2VfMsg1NT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e20fc8d4-968c-4272-9c62-57eeefcee1b3"
      },
      "source": [
        "model.evaluate(test_x,test_y)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 1s 145ms/step - loss: 0.0098\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.009824990294873714"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oNuY-45SngR",
        "colab_type": "text"
      },
      "source": [
        "INFERENCE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTfYjsyJTEtv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create some sample data\n",
        "X, Y = convert(x_test, y_test)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPazH1zFTnE4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "535d81f5-7835-47ce-98a0-6d78bfe13c78"
      },
      "source": [
        "# get prediction for one sample\n",
        "y_pred = model.predict(X)\n",
        "y_pred.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 3150, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrD03dgjcZMO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "OBJperCLASS = 10 # get the top 10 results for each class\n",
        "# get the confidence scores (with class values) and delta for the boxes. For each class, the top 10 values are used\n",
        "def infer(Y):\n",
        "  # classes are actually the index into the default boxes\n",
        "  classes = np.zeros((OBJperCLASS,outputChannels-4),dtype=np.uint16)\n",
        "  conf = np.zeros((OBJperCLASS,outputChannels-4))\n",
        "  delta = np.zeros((OBJperCLASS,outputChannels-4,4))\n",
        "  class_predictions = softmax(Y[:,:outputChannels-4],axis=1)\n",
        "  for i in range(outputChannels-4):\n",
        "    classes[:,i] = bottleneck.argpartition(class_predictions[:,i],BOXES-1-10,axis=-1)[-OBJperCLASS:]\n",
        "    conf[:,i] = class_predictions[classes[:,i],i]\n",
        "    delta[:,i] = Y[classes[:,i],outputChannels-4:]\n",
        "  return conf,classes, delta\n",
        "\n",
        "# generate bounding boxes from the inferred outputs\n",
        "def Bbox(confidence,box_idx,delta):\n",
        "  #delta contains delta(cx,cy,h,w)\n",
        "  bbox_centre = np.zeros((OBJperCLASS,outputChannels-4,2))\n",
        "  bbox_hw = np.zeros((OBJperCLASS,outputChannels-4,2))\n",
        "  for i in range(OBJperCLASS):\n",
        "    bbox_centre[i,:,0] = centres[box_idx[i]][:,0]+delta[i,:,0]\n",
        "    bbox_centre[i,:,1] = centres[box_idx[i]][:,1]+delta[i,:,1]\n",
        "    bbox_hw[i,:,0] = hw[box_idx[i]][:,0] + delta[i,:,2]\n",
        "    bbox_hw[i,:,1] = hw[box_idx[i]][:,1]+delta[i,:,3]\n",
        "  return bbox_centre,bbox_hw"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY7SOlpafX51",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "outputId": "eef5e296-27f6-46f1-bfeb-422573f1d1e1"
      },
      "source": [
        "r = np.random.randint(TESTSIZE)\n",
        "\n",
        "# top 10 predictions for each class\n",
        "confidence, box_idx, delta = infer(y_pred[r])\n",
        "bbox_centre,bbox_hw = Bbox(confidence, box_idx, delta)\n",
        "\n",
        "im = np.array(Image.fromarray(X[r].astype(np.uint8)))\n",
        "fig,ax = plt.subplots(1)\n",
        "ax.imshow(im)\n",
        "\n",
        "for i in range(outputChannels-4):\n",
        "  # skipping backgrounds\n",
        "  if i == NUM_CLASSES:\n",
        "    continue\n",
        "  color = 'r'\n",
        "  # if a class is mentioned in the ground truth, color the boxes green\n",
        "  if i in Y[r,:,0]:\n",
        "    color = 'g'\n",
        "    print(i)\n",
        "  \n",
        "  # skip all the classes which have low confidence values\n",
        "  if (confidence[:,i] > 0.5).any() or i in Y[r,:,0]:\n",
        "    for k in range(OBJperCLASS):\n",
        "      print(\"{}: Confidence-{}\\t\\tCentre-{} Height,Width-{}\".format(i,confidence[k,i],bbox_centre[k,i],bbox_hw[k,i]))\n",
        "      \n",
        "      # draw bounding box only if confidence scores are high\n",
        "      if confidence[k,i] < 0.5:\n",
        "        continue\n",
        "      x = bbox_centre[k,i,0] - bbox_hw[k,i,0]/2\n",
        "      y = bbox_centre[k,i,1] - bbox_hw[k,i,1]/2\n",
        "      rect = patches.Rectangle((y,x),bbox_hw[k,i,1],bbox_hw[k,i,0],linewidth=1,edgecolor=color,facecolor='none')\n",
        "      ax.add_patch(rect)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n",
            "7: Confidence-0.7365235686302185\t\tCentre-[42.19794345 98.16143656] Height,Width-[32.29747125 32.31169936]\n",
            "7: Confidence-0.8857401013374329\t\tCentre-[31.7246573  91.92364167] Height,Width-[38.88492426 28.39619501]\n",
            "7: Confidence-0.9466167688369751\t\tCentre-[37.35820007 95.4094162 ] Height,Width-[28.65339181 29.04177281]\n",
            "7: Confidence-0.9956559538841248\t\tCentre-[37.51727843 93.68477857] Height,Width-[27.14049515 28.02397426]\n",
            "7: Confidence-0.9956580996513367\t\tCentre-[36.07167462 96.26651478] Height,Width-[27.35519641 40.82926547]\n",
            "7: Confidence-0.9860585927963257\t\tCentre-[36.14206849 88.0132165 ] Height,Width-[26.96784037 42.68980633]\n",
            "7: Confidence-0.9980512857437134\t\tCentre-[35.96905352 92.87503022] Height,Width-[27.35304659 40.9342879 ]\n",
            "7: Confidence-0.9995020627975464\t\tCentre-[39.372262   93.71296859] Height,Width-[28.78150412 28.83308884]\n",
            "7: Confidence-0.9984629154205322\t\tCentre-[38.21918631 94.18664432] Height,Width-[27.11899134 27.2651076 ]\n",
            "7: Confidence-0.9972821474075317\t\tCentre-[37.71326017 92.93149531] Height,Width-[29.38378605 28.26766874]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z32HPrzihVqN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 34,
      "outputs": []
    }
  ]
}